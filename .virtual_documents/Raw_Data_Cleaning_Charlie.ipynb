# Import Dependencies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import scipy.stats as stats


# Read in .csv dataset, 1999

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_1999.csv'
CVD_1999_df = pd.read_csv(path)
CVD_1999_df["year"] = CVD_1999_df["year"].astype(float)
CVD_1999_df.info()


# Read in .csv dataset, 2000

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2000.csv'
CVD_2000_df = pd.read_csv(path)
CVD_2000_df["year"] = CVD_2000_df["year"].astype(float)
CVD_2000_df.info()


# Read in .csv dataset, 2001

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2001.csv'
CVD_2001_df = pd.read_csv(path)
CVD_2001_df["year"] = CVD_2001_df["year"].astype(float)
CVD_2001_df.info()


# Read in .csv dataset, 2002

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2002.csv'
CVD_2002_df = pd.read_csv(path)
CVD_2002_df["year"] = CVD_2002_df["year"].astype(float)
CVD_2002_df.info()


# Read in .csv dataset, 2003

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2003.csv'
CVD_2003_df = pd.read_csv(path)
CVD_2003_df["year"] = CVD_2003_df["year"].astype(float)
CVD_2003_df.info()


# Read in .csv dataset, 2004

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2004.csv'
CVD_2004_df = pd.read_csv(path)
CVD_2004_df["year"] = CVD_2004_df["year"].astype(float)
CVD_2004_df.info()


# Read in .csv dataset, 2005

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2005.csv'
CVD_2005_df = pd.read_csv(path)
CVD_2005_df["year"] = CVD_2005_df["year"].astype(float)
CVD_2005_df.info()


# Read in .csv dataset, 2006

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2006.csv'
CVD_2006_df = pd.read_csv(path)
CVD_2006_df["year"] = CVD_2006_df["year"].astype(float)
CVD_2006_df.info()


# Read in .csv dataset, 2007

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2007.csv'
CVD_2007_df = pd.read_csv(path)
CVD_2007_df["year"] = CVD_2007_df["year"].astype(float)
CVD_2007_df.info()


# Read in .csv dataset, 2008

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2008.csv'
CVD_2008_df = pd.read_csv(path)
CVD_2008_df["year"] = CVD_2008_df["year"].astype(float)
CVD_2008_df.info()


# Read in .csv dataset, 2009

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2009.csv'
CVD_2009_df = pd.read_csv(path)
CVD_2009_df["year"] = CVD_2009_df["year"].astype(float)
CVD_2009_df.info()


# Read in .csv dataset, 2010

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2010.csv'
CVD_2010_df = pd.read_csv(path)
CVD_2010_df["year"] = CVD_2010_df["year"].astype(float)
CVD_2010_df.info()


# Read in .csv dataset, 2011

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2011.csv'
CVD_2011_df = pd.read_csv(path)
CVD_2011_df["year"] = CVD_2011_df["year"].astype(float)
CVD_2011_df.info()


# Read in .csv dataset, 2012

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2012.csv'
CVD_2012_df = pd.read_csv(path)
CVD_2012_df["year"] = CVD_2012_df["year"].astype(float)
CVD_2012_df.info()


# Read in .csv dataset, 2013

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2013.csv'
CVD_2013_df = pd.read_csv(path)
CVD_2013_df["year"] = CVD_2013_df["year"].astype(float)
CVD_2013_df.info()


# Read in .csv dataset, 2014

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2014.csv'
CVD_2014_df = pd.read_csv(path)
CVD_2014_df["year"] = CVD_2014_df["year"].astype(float)
CVD_2014_df.info()


# Read in .csv dataset, 2015

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2015.csv'
CVD_2015_df = pd.read_csv(path)
CVD_2015_df["year"] = CVD_2015_df["year"].astype(float)
CVD_2015_df.info()


# Read in .csv dataset, 2016

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2016.csv'
CVD_2016_df = pd.read_csv(path)
CVD_2016_df["year"] = CVD_2016_df["year"].astype(float)
CVD_2016_df.info()


# Read in .csv dataset, 2017

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2017.csv'
CVD_2017_df = pd.read_csv(path)
CVD_2017_df["year"] = CVD_2017_df["year"].astype(float)
CVD_2017_df.info()


# Read in .csv dataset, 2018

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2018.csv'
CVD_2018_df = pd.read_csv(path)
CVD_2018_df["year"] = CVD_2018_df["year"].astype(float)
CVD_2018_df.info()


# Read in .csv dataset, 2019

path = 'Resources/CDC_Rates_in_Heart_Disease_and_Stroke_Mortality_Among_US_Adults_By_State_Race_Ethnicity_and_Sex_2019.csv'
CVD_2019_df = pd.read_csv(path)
CVD_2019_df["year"] = CVD_2019_df["year"].astype(float)
CVD_2019_df.info()


# Drop any rows with null values, 1999
Clean_CVD_1999_df = CVD_1999_df.dropna(axis=0, how = "all")
Clean_CVD_1999_df.head()


# Drop any rows with null values, 2000
Clean_CVD_2000_df = CVD_2000_df.dropna(axis=0, how = "all")
Clean_CVD_2000_df.head()


# Drop any rows with null values, 2001
Clean_CVD_2001_df = CVD_2001_df.dropna(axis=0, how = "all")
Clean_CVD_2001_df.head()


# Drop any rows with null values, 2002
Clean_CVD_2002_df = CVD_2002_df.dropna(axis=0, how = "all")
Clean_CVD_2002_df.head()


# Drop any rows with null values, 2003
Clean_CVD_2003_df = CVD_2003_df.dropna(axis=0, how = "all")
Clean_CVD_2003_df.head()


# Drop any rows with null values, 2004
Clean_CVD_2004_df = CVD_2004_df.dropna(axis=0, how = "all")
Clean_CVD_2004_df.head()


# Drop any rows with null values, 2005
Clean_CVD_2005_df = CVD_2005_df.dropna(axis=0, how = "all")
Clean_CVD_2005_df.head()


# Drop any rows with null values, 2006
Clean_CVD_2006_df = CVD_2006_df.dropna(axis=0, how = "all")
Clean_CVD_2006_df.head()


# Drop any rows with null values, 2007
Clean_CVD_2007_df = CVD_2007_df.dropna(axis=0, how = "all")
Clean_CVD_2007_df.head()


# Drop any rows with null values, 2008
Clean_CVD_2008_df = CVD_2008_df.dropna(axis=0, how = "all")
Clean_CVD_2008_df.head()


# Drop any rows with null values, 2009
Clean_CVD_2009_df = CVD_2009_df.dropna(axis=0, how = "all")
Clean_CVD_2009_df.head()


# Drop any rows with null values, 2010
Clean_CVD_2010_df = CVD_2010_df.dropna(axis=0, how = "all")
Clean_CVD_2010_df.head()


# Drop any rows with null values, 2011
Clean_CVD_2011_df = CVD_2011_df.dropna(axis=0, how = "all")
Clean_CVD_2011_df.head()


# Drop any rows with null values, 2012
Clean_CVD_2012_df = CVD_2012_df.dropna(axis=0, how = "all")
Clean_CVD_2012_df.head()


# Drop any rows with null values, 2013
Clean_CVD_2013_df = CVD_2013_df.dropna(axis=0, how = "all")
Clean_CVD_2013_df.head()


# Drop any rows with null values, 2014
Clean_CVD_2014_df = CVD_2014_df.dropna(axis=0, how = "all")
Clean_CVD_2014_df.head()


# Drop any rows with null values, 2015
Clean_CVD_2015_df = CVD_2015_df.dropna(axis=0, how = "all")
Clean_CVD_2015_df.head()


# Drop any rows with null values, 2016
Clean_CVD_2016_df = CVD_2016_df.dropna(axis=0, how = "all")
Clean_CVD_2016_df.head()


# Drop any rows with null values, 2017
Clean_CVD_2017_df = CVD_2017_df.dropna(axis=0, how = "all")
Clean_CVD_2017_df.head()


# Drop any rows with null values, 2018
Clean_CVD_2018_df = CVD_2018_df.dropna(axis=0, how = "all")
Clean_CVD_2018_df.head()


# Drop any rows with null values, 2019
Clean_CVD_2019_df = CVD_2019_df.dropna(axis=0, how = "all")
Clean_CVD_2019_df.head()


## Rename original columns, 1999
Renamed_CVD_1999 = Clean_CVD_1999.rename(columns = {"LocationAbbr": "US States", "LocationDesc": "US County",\
                                                               "Topic": "CVD Type", "Data_Value_Unit": "Rate per 100,000 population",\
                                                               "Stratification1": "Age range", "Stratification2": "Ethnicity", "Stratification3": "Gender"})
Renamed_CVD_1999.head()


## Rename original columns, 2000



## Rename original columns, 2001



## Rename original columns, 2002



## Rename original columns, 2003



## Rename original columns, 2004



## Rename original columns, 2005



## Rename original columns, 2006



## Rename original columns, 2007



## Rename original columns, 2008



## Rename original columns, 2009



## Rename original columns, 2010



## Rename original columns, 2011



## Rename original columns, 2012



## Rename original columns, 2013



## Rename original columns, 2014



## Rename original columns, 2015



## Rename original columns, 2016



## Rename original columns, 2017



## Rename original columns, 2018



## Rename original columns, 2019



# Show a list of all the different states in the dataset.

## NOTE: this will need to be updated to loop through all the years now
#state_list = Heart_disease_rename['US States'].unique().tolist()
#state_list


# Group by the specified columns and calculate the mean for 'Data_Value/100_000 People' by County

## THis will need to be updated to append all the years together

# Averaged_grouped_df = Heart_disease_rename.groupby(['US States', 'Year', 'Ethnicity', 'Gender', 'CVD Type','Age range'], as_index=False).mean()
# ^^ So basically it takes any rows that have the same values in columns 'US States', 
# 'Year' 'Ethnicity' , 'Gender', 'Heart Disease Type' and 'Age range'
# and finds the average of those rows then returns a data frame with
# one value (average) for the 'Data_Value/100_000 People'.


Averaged_grouped_df


# Filtered DF to check if above is correct:
# Filter the DataFrame

df = Heart_disease_rename

filtered_df = df[
    (df['US States'] == 'AK') &
    (df['Year'] == 1999.0) &
    (df['Ethnicity'] == 'American Indian/Alaska Native') &
    (df['Gender'] == 'Overall') &
    (df['Heart Disease Type'] == 'All heart disease') &
    (df['Age range'] == 'Ages 65 years and older')
]

filtered_df


Averaged_grouped_df.to_csv('Averaged_Cleaned_filtered_data.csv', index=False)



